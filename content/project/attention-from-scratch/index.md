---
title: Attention From Scratch
summary: Building an end-to-end inference stack for open-source LLMs and documenting lessons learned.
date: 2025-01-01
links:
  - icon: github
    icon_pack: fab
    name: Code
    url: https://github.com/mauer4/Attention-From-Scratch
tags: [LLM, CUDA, Inference]
featured: false
---

This project explores how far a single engineer can go by combining open-source large language models with enterprise-class GPUs rented on demand. I'm documenting design choices, profiling results, and the infrastructure needed to run models such as Olmo 2 with production-grade reliability.
