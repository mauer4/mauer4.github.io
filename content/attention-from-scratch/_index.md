---
title: Attention From Scratch
date: 2025-01-01
type: page

outputs: [HTML]

design:
  spacing: '4rem'

hero:
  enable: true
  image:
    # Use a subtle gradient background instead of an image
    placement: full

---

I would like to build a project to code AI inference transformers from scratch for an open source LLM — that is, use open-source LLM weights and implement all inference code and kernels top-to-bottom, including prefill, decode, and serving. I plan to develop and run this on rented NVIDIA server GPUs via Vast.ai. This is a realistic, first‑principles path toward learning how to implement and operate a production‑level LLM inference stack on cloud, enterprise‑grade CPU/GPU hardware.

{{< attention_timeline >}}
